{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba814a-8117-4071-a986-93cff7495d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script was originally written in Korean. Comments and string literals have been translated into English for wider accessibility.\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from kobert_transformers import get_tokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Input CSV file\n",
    "input_filename = \"03_cleaned_dc_bitcoin_data.csv\"\n",
    "input_file_path = f\"../data/{input_filename}\"\n",
    "\n",
    "# Output CSV file\n",
    "output_filename = \"05_kobert_baseline_test_output_1k.csv\"\n",
    "output_file_path = f\"../data/{output_filename}\"\n",
    "\n",
    "# 1. Load Tokenizer and Model\n",
    "kobert_tokenizer = get_tokenizer()\n",
    "\n",
    "MODEL_NAME = \"monologg/kobert\"\n",
    "NUM_LABELS = 3  # Assuming 3 labels (positive, negative, neutral)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. Define Test Dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "# 3. Read CSV file (use 'Title' column)\n",
    "# Assumes the input CSV has an English header 'Title' (translated from '제목')\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Check CSV column names\n",
    "print(\"CSV Columns:\", df.columns)\n",
    "\n",
    "# Extract text data from 'Title' column\n",
    "texts = df[\"Title\"].fillna(\"\").tolist() # Changed '제목' to 'Title'\n",
    "\n",
    "# Use only the top 1000 data entries for testing\n",
    "texts = texts[:1000]\n",
    "\n",
    "# 4. Create Dataset and DataLoader\n",
    "test_dataset = TestDataset(texts, kobert_tokenizer, max_length=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 5. Perform Inference\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Inference\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            results.append({\n",
    "                \"pred_label\": int(preds[i]),\n",
    "                \"prob_0\": float(probs[i][0]),\n",
    "                \"prob_1\": float(probs[i][1]),\n",
    "                \"prob_2\": float(probs[i][2]) if NUM_LABELS == 3 else None\n",
    "            })\n",
    "\n",
    "# 6. Save Results\n",
    "results_df = pd.DataFrame(results)\n",
    "final_df = pd.concat([df[:1000], results_df], axis=1)\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Inference complete. Results saved to '{output_file_path}'.\") # Changed from \"추론 완료. 결과가 ...에 저장되었습니다.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

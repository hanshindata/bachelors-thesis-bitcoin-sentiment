{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6ccc2-d097-44b1-9923-b8d300c850fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script was originally written in Korean. Comments and string literals have been translated into English for wider accessibility.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Selenium settings\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.set_page_load_timeout(60)  # Set page load timeout (seconds)\n",
    "\n",
    "# Set page range for crawling\n",
    "BASE_URL = \"https://gall.dcinside.com/board/lists/?id=bitcoins_new1&page=\"\n",
    "start_page = 26400\n",
    "end_page = 30000  # Target end page\n",
    "data = []\n",
    "save_interval = 100  # Data saving interval (pages)\n",
    "\n",
    "# Data saving function\n",
    "def save_data_to_csv(data, filename=\"01_dc_bitcoin_data.csv\"):\n",
    "    df = pd.DataFrame(data)\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, encoding='utf-8-sig', index=False)  # Append to existing file\n",
    "    else:\n",
    "        df.to_csv(filename, encoding='utf-8-sig', index=False)  # Create new file\n",
    "    print(f\"Saved {len(data)} data items.\")  # Changed from \"{len(data)}개의 데이터를 저장했습니다.\"\n",
    "    data.clear()  # Updated print statement\n",
    "\n",
    "# Page crawling function\n",
    "def fetch_page_data(page):\n",
    "    try:\n",
    "        driver.get(BASE_URL + str(page))\n",
    "        time.sleep(2)  # Wait for page to load\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        articles = soup.select('tbody > tr.ub-content')  # Select article rows\n",
    "\n",
    "        page_data = []\n",
    "        for article in articles:\n",
    "            gall_no = article.select_one('td.gall_num').text.strip()\n",
    "            if not gall_no.isdigit():  # Skip if ID is not a digit (likely an advertisement)\n",
    "                continue\n",
    "\n",
    "            title = article.select_one('td.gall_tit > a').text.strip()\n",
    "            date = article.select_one('td.gall_date').text.strip()\n",
    "            views = article.select_one('td.gall_count').text.strip()\n",
    "            recommends = article.select_one('td.gall_recommend').text.strip()\n",
    "\n",
    "            page_data.append({\n",
    "                'Post_ID': gall_no, # Changed from '게시물 번호'\n",
    "                'Title': title,     # Changed from '제목'\n",
    "                'Date': date,       # Changed from '작성일'\n",
    "                'Views': views,     # Changed from '조회수'\n",
    "                'Recommends': recommends # Changed from '추천수'\n",
    "            })\n",
    "        return page_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main crawling loop\n",
    "try:\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        print(f\"Crawling page {page}...\") # Changed from \"{page}페이지 크롤링 중...\"\n",
    "        page_data = fetch_page_data(page)\n",
    "        data.extend(page_data)\n",
    "\n",
    "        if page % save_interval == 0 or page == end_page:  # Save data periodically\n",
    "            save_data_to_csv(data)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Crawling interrupted.\") # Changed from \"크롤링이 중단되었습니다.\"\n",
    "finally:\n",
    "    # 남은 데이터 저장\n",
    "    if data:\n",
    "        save_data_to_csv(data)\n",
    "    driver.quit()\n",
    "    print(\"Crawling finished.\") # Changed from \"크롤링 종료\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
